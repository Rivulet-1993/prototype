model:                    # architecture details
    type: resnet50        # model name
    kwargs:
        num_classes: 6    # number of classes
        bn:
            use_sync_bn: False  # whether to use syncbn
            kwargs: {}          # kwargs of bn

dist:                     # distributed communication
    sync: False           # if 'True', synchronize gradients after forward 
                          # if 'False', synchronize gradient during forward

optimizer:                # optimizer details
    type: SGD
    kwargs:
        nesterov: True
        momentum: 0.9
        weight_decay: 0.0001

lr_scheduler:             # learning rate scheduler details
    type: Step
    kwargs:
        lr_steps: [37500, 75000, 112500]
        lr_mults: [0.1, 0.1, 0.1]

        base_lr: 0.1        # initial leaning rate 
        warmup_lr: 0.4      # learning rate after warming up
        warmup_steps: 2500  # iterations of warmup
        max_iter: 125000    # total iterations of training

label_smooth: 0.1         # label smooth ratio
# mixup: 0.2              # mixup ratio
# cutmix: 1.0             # cutmix ratio
ema:                      # exponential moving average details
    enable: False
    kwargs:
        decay: 0.999

lms:                      # large model support: utilize cpu to save gpu memory
    enable: False         # whether to use lms
    kwargs:
        limit: 12         # the soft limit in G-bytes on GPU memory allocated for tensors

data:                     # data details
    type: custom          # choices = {'imagenet', 'custom'}
    read_from: osg        # choices = {'mc', 'fs', 'fake', 'osg'}
    use_dali: False       # whether to use NVIDIA dali dataloader
    batch_size: 64        # batch size in one GPU
    num_workers: 4        # number of subprocesses for data loading
    pin_memory: True      # whether to copy Tensors into CUDA pinned memory
    input_size: 224       # training image size
    test_resize: 256      # testing resize image size

    train:                            # training data details
        meta_file: /mnt/lustrenew/yuankun/train.jsonl
        osg_server: 10.198.3.28:30080/components/osg-default
        image_reader:                 # image decoding type
            type: pil
        sampler:                      # sampler details
            type: distributed_iteration  # distributed iteration-based sampler
        transforms:                   # torchvision transforms, flexible
            - type: to_grayscale
              kwargs:
                  num_output_channels: 3
            - type: adjust_gamma
              kwargs:
                  gamma: 1
            - type: resize
              kwargs:
                  size: [224, 224]
            - type: color_jitter
              kwargs:
                  brightness: 0.3
                  contrast: 0.1
                  saturation: 0.1
            - type: random_orientation_rotation
              kwargs:
                  angles: [0, 90, 180, 270]
            - type: random_horizontal_flip
            - type: ramdom_vertical_flip
            - type: to_tensor
            - type: normalize
              kwargs:
                  mean: [0.485, 0.456, 0.406]
                  std: [0.229, 0.224, 0.225]

    test:                             # testing data details
        meta_file: /mnt/lustrenew/yuankun/test.jsonl
        osg_server: 10.198.3.28:30080/components/osg-default
        image_reader:
            # type: pil
            type: kestrel             # decoding use kestrel type, the same with kestrel SDK
            ues_gpu: False            # if kestrel_caffe, True; if kestrel_ppl/nnie, False; if True, num_workers should be 0
        sampler:                      # sampler details
            type: distributed         # non-repeated sampling
        transforms:                   # torchvision transforms, flexible
            - type: to_grayscale
              kwargs:
                  num_output_channels: 3
            - type: adjust_gamma
              kwargs:
                  gamma: 1
            - type: resize
              kwargs:
                  size: [224, 224]
            - type: to_tensor
            - type: normalize
              kwargs:
                  mean: [124.16, 116.736, 103.936]
                  std: [58.624, 57.344, 57.6]
                #   mean: [0.485, 0.456, 0.406]
                #   std: [0.229, 0.224, 0.225]

        evaluator:
            type: custom
            kwargs:
                key_metric: fp@0.95recall
                defect_classes: [3, 4]
                recall_thres: [1.0, 0.95, 0.90, 0.8, 0.7]
                tpr_thres: [0.99, 0.98, 0.97, 0.95, 0.9]

saver:                                # saving or loading details
    print_freq: 10                    # frequence of printing logger
    val_freq: 100                     # frequence of evaluating during training
    save_many: False                  # whether to save checkpoints after every evaluation
    # pretrain:                       # pretrain model details
    #     path: /mnt/lustre/share/prototype_model_zoo/resnet50_batch1k_epoch100_nesterov_wd0.0001/checkpoints/ckpt.pth.tar
    #     ignore:                     # ignore keys in checkpoints
    #         key:                    # if training from scratch, pop 'optimzier' and 'last_iter'
    #             - optimizer         # if resuming from ckpt, DO NOT pop them
    #             - last_iter
    #         model:                  # ignore modules in model
    #             - module.fc.weight  # if training with different number of classes, pop the keys 
    #             - module.fc.bias    # of last fully-connected layers

to_kestrel:
    model_name: KM_Classifier_Project_Test
    version: '1.0.0'
    add_softmax: True
    pixel_means: [124.16, 116.736, 103.936]
    pixel_stds: [58.624, 57.344, 57.6]
    is_rgb: True
    save_all_label: True
    type: 'UNKNOWN'
    class_label:
        label_name:
            calculator: 'bypass'
            start: 0
            end: 5
            labels: ['apple', 'banana', 'orange', 'dog', 'cat', 'bird']
